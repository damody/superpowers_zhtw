# 來自用戶反饋的技能改進

**日期：** 2025-11-28
**狀態：** 草稿
**來源：** 在真實開發場景中使用 superpowers 的兩個 Claude 實例

---

## 執行摘要

兩個 Claude 實例提供了來自實際開發會話的詳細反饋。他們的反饋揭示了**當前技能中的系統性差距**，這些差距允許可預防的錯誤儘管遵循了技能也被發運。

**關鍵洞察：** 這些是問題報告，不只是解決方案提案。問題是真實的；解決方案需要仔細評估。

**關鍵主題：**
1. **驗證差距** - 我們驗證操作成功但不驗證它們實現預期結果
2. **流程衛生** - 背景進程累積並幹擾跨 subagents
3. **上下文優化** - Subagents 獲得太多不相關的信息
4. **缺少自反思** - 沒有提示在交接前批評自己的工作
5. **模擬安全** - 模擬可以在不檢測的情況下從接口分歧
6. **技能激活** - 技能存在但沒有被閱讀/使用

---

## 已識別的問題

### 問題 1：配置變更驗證差距

**發生了什麼：**
- Subagent 測試了「OpenAI 集成」
- 設置了 `OPENAI_API_KEY` 環境變數
- 獲得 status 200 回應
- 報告「OpenAI 集成工作」
- **但** 回應包含 `"model": "claude-sonnet-4-20250514"` - 實際上在使用 Anthropic

**根本原因：**
`verification-before-completion` 檢查操作成功但不驗證結果反映預期的配置變更。

**影響：** 高 - 集成測試中的錯誤信心，錯誤被發運到生產

**示例失敗模式：**
- 切換 LLM 提供程序 → 驗證 status 200 但不檢查模型名稱
- 啟用功能旗標 → 驗證無錯誤但不檢查功能是否活躍
- 更改環境 → 驗證部署成功但不檢查環境變數

---

### 問題 2：背景進程累積

**發生了什麼：**
- 會話期間派遣多個 subagents
- 每個啟動了背景伺服器進程
- 進程累積（4+ 個伺服器運行）
- 舊進程仍綁定到端口
- 稍後 E2E 測試撞上舊伺服器，配置錯誤
- 令人困惑/不正確的測試結果

**根本原因：**
Subagents 是無狀態的 - 不知道前面的 subagents 的進程。沒有清理協議。

**影響：** 中等-高 - 測試撞上錯誤的伺服器，假通過/失敗，調試混淆

---

### 問題 3：Subagent 提示中的上下文膨脹

**發生了什麼：**
- 標準方法：給 subagent 完整計劃文件讀取
- 實驗：只給任務 + 模式 + 文件 + 驗證命令
- 結果：更快、更專注、單次嘗試完成更常見

**根本原因：**
Subagents 浪費令牌和關注力在不相關的計劃部分。

**影響：** 中等 - 執行較慢，更多失敗的嘗試

**什麼工作了：**
```
你在向 packnplay 的測試套件添加單個 E2E 測試。

**你的任務：** 將 `TestE2E_FeaturePrivilegedMode` 添加到 `pkg/runner/e2e_test.go`

**測試內容：** 在其元數據中請求 `"privileged": true` 的本地 devcontainer 功能應導致容器以 `--privileged` 旗標運行。

**遵循 TestE2E_FeatureOptionValidation 的確切模式**（在文件末尾）

**寫入後，運行：** `go test -v ./pkg/runner -run TestE2E_FeaturePrivilegedMode -timeout 5m`
```

---

### 問題 4：交接前沒有自反思

**發生了什麼：**
- 添加了自反思提示：「用新鮮的眼光看你的工作 - 什麼可以更好？」
- 任務 5 的實現者在自反思期間識別了失敗測試是由於實現錯誤，不是測試錯誤
- 跟蹤到第 99 行：`strings.Join(metadata.Entrypoint, " ")` 創建無效 Docker 語法
- 沒有自反思，會剛剛報告「測試失敗」，沒有根本原因

**根本原因：**
實現者在報告完成前不自然地後退並批評他們的工作。

**影響：** 中等 - 錯誤交接給審查者，實現者本可以捕獲

---

### 問題 5：模擬-接口分歧

**發生了什麼：**
```typescript
// 接口定義 close()
interface PlatformAdapter {
  close(): Promise<void>;
}

// 代碼（錯誤的）調用 cleanup()
await adapter.cleanup();

// 模擬（匹配錯誤）定義 cleanup()
vi.mock('web-adapter', () => ({
  WebAdapter: vi.fn().mockImplementation(() => ({
    cleanup: vi.fn().mockResolvedValue(undefined),  // 錯誤！
  })),
}));
```
- 測試通過
- 運行時崩潰：「adapter.cleanup is not a function」

**根本原因：**
模擬來自錯誤代碼調用的內容，不是來自接口定義。TypeScript 無法用錯誤的方法名捕獲內聯模擬。

**影響：** 高 - 測試給假信心，運行時崩潰

**為什麼 testing-anti-patterns 沒有防止：**
技能涵蓋測試模擬行為和在沒有理解的情況下模擬，但不是「從接口派生模擬，不是實現」的特定模式。

---

### 問題 6：代碼審查者文件訪問

**發生了什麼：**
- 代碼審查者 subagent 派遣
- 無法找到測試文件：「文件在倉庫中似乎不存在」
- 文件實際存在
- 審查者不知道首先顯式讀取它

**根本原因：**
審查者提示不包括顯式文件閱讀說明。

**影響：** 低-中等 - 審查失敗或不完整

---

### 問題 7：修復工作流延遲

**發生了什麼：**
- 實現者在自反思期間識別錯誤
- 實現者知道修復
- 當前工作流：報告 → 我派遣修復者 → 修復者修復 → 我驗證
- 額外的往返增加延遲，沒有增加價值

**根本原因：**
實現者和修復者角色之間的僵硬分離，當實現者已經診斷時。

**影響：** 低 - 延遲，但沒有正確性問題

---

### 問題 8：技能未被閱讀

**發生了什麼：**
- `testing-anti-patterns` 技能存在
- 人類和 subagents 都沒有在寫測試前讀它
- 會預防一些問題（儘管不是全部 - 見問題 5）

**根本原因：**
沒有執行 subagents 讀相關技能。沒有提示包括技能閱讀。

**影響：** 中等 - 技能投資被浪費如果不使用

---

## 提議的改進

### 1. verification-before-completion：添加配置變更驗證

**添加新部分：**

```markdown
## 驗證配置變更

當測試配置、提供程序、功能旗標或環境的變更時：

**不要只驗證操作成功。驗證輸出反映預期的變更。**

### 常見失敗模式

操作成功，因為*某*有效的配置存在，但它不是你意圖測試的配置。

### 示例

| 變更 | 不足 | 需要 |
|--------|-------------|----------|
| 切換 LLM 提供程序 | Status 200 | 回應包含預期的模型名稱 |
| 啟用功能旗標 | 無錯誤 | 功能行為實際活躍 |
| 更改環境 | 部署成功 | 日誌/變數引用新環境 |
| 設置憑證 | 認證成功 | 認證用戶/上下文正確 |

### 門函數

```
聲稱配置變更工作前：

1. 識別：此變更後什麼應該不同？
2. 定位：該區別在哪裡可見？
   - 回應字段（模型名稱、用戶 ID）
   - 日誌行（環境、提供程序）
   - 行為（功能活躍/不活躍）
3. 運行：顯示可見區別的命令
4. 驗證：輸出包含預期的區別
5. 只有那時：聲稱配置變更工作

危險信號：
  - 「請求成功」，沒有檢查內容
  - 檢查狀態碼但不是回應體
  - 驗證無錯誤但不是正面確認
```

**為什麼這工作：**
強制驗證意圖，不只是操作成功。

---

### 2. subagent-driven-development：為 E2E 測試添加流程衛生

**添加新部分：**

```markdown
## E2E 測試的流程衛生

派遣啟動服務的 subagents（伺服器、資料庫、消息隊列）時：

### 問題

Subagents 是無狀態 - 他們不知道前面的 subagents 啟動的進程。背景進程持續並可以干擾後來的測試。

### 解決方案

**在派遣 E2E 測試 subagent 前，在提示中包括清理：**

```
在啟動任何服務前：
1. 殺死現有進程：pkill -f "<service-pattern>" 2>/dev/null || true
2. 等待清理：sleep 1
3. 驗證端口空閒：lsof -i :<port> && echo "錯誤：端口仍使用中" || echo "端口空閒"

測試完成後：
1. 殺死你啟動的進程
2. 驗證清理：pgrep -f "<service-pattern>" || echo "清理成功"
```

### 示例

```
任務：運行 API 伺服器的 E2E 測試

提示包括：
「在啟動伺服器前：
- 殺死任何現有伺服器：pkill -f 'node.*server.js' 2>/dev/null || true
- 驗證端口 3001 空閒：lsof -i :3001 && exit 1 || echo '端口可用'

測試後：
- 殺死你啟動的伺服器
- 驗證：pgrep -f 'node.*server.js' || echo '清理驗證'」
```

### 為什麼這很重要

- 舊進程用錯誤配置服務請求
- 端口衝突造成靜默失敗
- 進程累積會減慢系統
- 令人困惑的測試結果（撞上錯誤的伺服器）
```

**權衡分析：**
- 向提示添加樣板
- 但防止非常令人困惑的調試
- 對 E2E 測試 subagents 值得

---

### 3. subagent-driven-development：添加精簡上下文選項

**修改步驟 2：用 Subagent 執行任務**

**前：**
```
仔細讀取該任務從 [plan-file]。
```

**後：**
```
## 上下文方法

**完整計劃（默認）：**
用於複雜或有依賴的任務：
```
仔細讀取任務 N 從 [plan-file]。
```

**精簡上下文（對於獨立任務）：**
用於獨立和基於模式的任務：
```
你正在實現：[1-2 句子任務描述]

修改文件：[確切路徑]
遵循模式：[對現有函數/測試的引用]
實現什麼：[特定要求]
驗證：[確切命令運行]

[不要包括完整計劃文件]
```

**使用精簡上下文何時：**
- 任務遵循現有模式（添加類似測試，實現類似功能）
- 任務自包含（不需要其他任務的上下文）
- 模式引用足夠（例如「遵循 TestE2E_FeatureOptionValidation」）

**使用完整計劃何時：**
- 任務有對其他任務的依賴
- 需要理解整體架構
- 複雜邏輯需要上下文
```

**示例：**
```
精簡上下文提示：

「你在向 devcontainer 功能添加特權模式測試。

文件：pkg/runner/e2e_test.go
模式：遵循 TestE2E_FeatureOptionValidation（在文件末尾）
測試：元數據中帶 `"privileged": true` 的功能導致 `--privileged` 旗標
驗證：go test -v ./pkg/runner -run TestE2E_FeaturePrivilegedMode -timeout 5m

報告：實現、測試結果、任何問題。」
```

**為什麼這工作：**
減少令牌使用、增加焦點、適當時更快完成。

---

### 4. subagent-driven-development：添加自反思步驟

**修改步驟 2：用 Subagent 執行任務**

**向提示模板添加：**

```
完成後，在報告回之前：

用新鮮的眼光後退並審查你的工作。

問自己：
- 這實際上解決了指定的任務？
- 有我沒考慮的邊界情況？
- 我正確遵循了模式？
- 如果測試失敗，什麼是根本原因（實現錯誤 vs 測試錯誤）？
- 關於此實現什麼可以更好？

如果你在此反思期間識別了問題，現在修復它們。

然後報告：
- 你實現了什麼
- 自反思發現（如果有）
- 測試結果
- 文件改變
```

**為什麼這工作：**
在交接前捕獲實現者可以發現的錯誤。文檔化的案例：通過自反思識別 entrypoint 錯誤。

**權衡：**
每個任務添加 ~30 秒，但交接前捕獲問題。

---

### 5. requesting-code-review：添加顯式文件閱讀

**修改代碼審查者模板：**

**在開始時添加：**

```markdown
## 要審查的文件

審查前，閱讀這些文件：

1. [列出在差異中改變的特定文件]
2. [由改變引用但未修改的文件]

使用讀取工具加載每個文件。

如果你無法找到文件：
- 檢查來自差異的確切路徑
- 嘗試備用位置
- 報告：「無法定位 [路徑] - 請驗證文件存在」

在你讀取實際代碼前不要繼續審查。
```

**為什麼這工作：**
顯式說明防止「文件未找到」問題。

---

### 6. testing-anti-patterns：添加模擬-接口分歧反模式

**添加新反模式 6：**

```markdown
## 反模式 6：來自實現的模擬

**違反：**
```typescript
// 代碼（錯誤的）調用 cleanup()
await adapter.cleanup();

// 模擬（匹配錯誤）有 cleanup()
const mock = {
  cleanup: vi.fn().mockResolvedValue(undefined)
};

// 接口（正確的）定義 close()
interface PlatformAdapter {
  close(): Promise<void>;
}
```

**為什麼這錯誤：**
- 模擬將錯誤編碼到測試中
- TypeScript 無法用錯誤的方法名捕獲內聯模擬
- 測試通過因為代碼和模擬都錯誤
- 運行時崩潰當真實對象被使用

**修復：**
```typescript
// ✅ 好的：從接口派生模擬

// 步驟 1：打開接口定義（PlatformAdapter）
// 步驟 2：列出定義那裡的方法（close、initialize、等）
// 步驟 3：模擬確切那些方法

const mock = {
  initialize: vi.fn().mockResolvedValue(undefined),
  close: vi.fn().mockResolvedValue(undefined),  // 來自接口！
};

// 現在測試失敗因為代碼調用 cleanup() 不存在
// 那失敗透露代碼中的錯誤，在運行時前
```

### 門函數

```
寫任何模擬前：

  1. 停止 - 不要看被測代碼還沒有
  2. 查找：依賴的接口/類型定義
  3. 讀取：接口文件
  4. 列出：接口中定義的方法
  5. 模擬：只有那些方法，帶確切的名稱
  6. 不要：看你的代碼調用什麼

  如果你的測試失敗因為代碼調用不在模擬中的東西：
    ✅ 好的 - 測試發現你代碼中的錯誤
    修復代碼以調用正確的接口方法
    不是模擬

  危險信號：
    - 「我會模擬代碼調用的」
    - 從實現複製方法名
    - 沒有讀接口寫模擬
    - 「測試失敗所以我會添加此方法到模擬」
```

**檢測：**

當你看到運行時錯誤「X is not a function」且測試通過：
1. 檢查 X 是否被模擬
2. 比較模擬方法到接口方法
3. 尋找方法名不匹配
```

**為什麼這工作：**
直接解決來自反饋的失敗模式。

---

### 7. subagent-driven-development：要求涉及測試的任務的技能閱讀

**添加到涉及測試的任務提示模板：**

```markdown
在寫任何測試前：

1. 讀測試反模式技能：
   使用技能工具：superpowers:testing-anti-patterns

2. 在以下時應用門函數來自那個技能：
   - 寫模擬
   - 向生產類添加方法
   - 模擬依賴

此非可選。違反反模式的測試將在審查中被拒絕。
```

**為什麼這工作：**
確保技能實際被使用，不只存在。

**權衡：**
添加時間到每個任務，但防止整個錯誤類別。

---

### 8. subagent-driven-development：允許實現者修復自識別的問題

**修改步驟 2：**

**當前：**
```
Subagent 報告回工作摘要。
```

**提議：**
```
Subagent 執行自反思，然後：

如果自反思識別可修復的問題：
  1. 修復問題
  2. 重新運行驗證
  3. 報告：「初始實現 + 自反思修復」

否則：
  報告：「實現完成」

在報告中包括：
- 自反思發現
- 是否應用了修復
- 最終驗證結果
```

**為什麼這工作：**
減少當實現者已知修復時的延遲。文檔化案例：會保存 entrypoint 錯誤的一個往返。

**權衡：**
稍微複雜提示，但更快端到端。

---

## 實現計劃

### 階段 1：高影響、低風險（先做）

1. **verification-before-completion：配置變更驗證**
   - 清晰添加，不改變現有內容
   - 解決高影響問題（測試中的假信心）
   - 文件：`skills/verification-before-completion/SKILL.md`

2. **testing-anti-patterns：模擬-接口分歧**
   - 添加新反模式，不修改現有
   - 解決高影響問題（運行時崩潰）
   - 文件：`skills/testing-anti-patterns/SKILL.md`

3. **requesting-code-review：顯式文件閱讀**
   - 簡單添加到模板
   - 修復具體問題（審查者找不到文件）
   - 文件：`skills/requesting-code-review/SKILL.md`

### 階段 2：中等改變（仔細測試）

4. **subagent-driven-development：流程衛生**
   - 添加新部分，不改變工作流
   - 解決中等-高影響（測試可靠性）
   - 文件：`skills/subagent-driven-development/SKILL.md`

5. **subagent-driven-development：自反思**
   - 改變提示模板（更高風險）
   - 但文檔化捕獲錯誤
   - 文件：`skills/subagent-driven-development/SKILL.md`

6. **subagent-driven-development：技能閱讀要求**
   - 添加提示開銷
   - 但確保技能實際被使用
   - 文件：`skills/subagent-driven-development/SKILL.md`

### 階段 3：優化（先驗證）

7. **subagent-driven-development：精簡上下文選項**
   - 添加複雜性（兩個方法）
   - 需要驗證它不造成混淆
   - 文件：`skills/subagent-driven-development/SKILL.md`

8. **subagent-driven-development：允許實現者修復**
   - 改變工作流（更高風險）
   - 優化，不錯誤修復
   - 文件：`skills/subagent-driven-development/SKILL.md`

---

## 開放問題

1. **精簡上下文方法：**
   - 我們應該將它變成基於模式任務的默認？
   - 我們如何決定使用哪個方法？
   - 太精簡和丟失重要上下文的風險？

2. **自反思：**
   - 這會顯著減慢簡單任務？
   - 應它只應用於複雜任務？
   - 我們如何防止「反思疲勞」它變成例行？

3. **流程衛生：**
   - 這應在 subagent-driven-development 或獨立技能？
   - 它應用到 E2E 測試以外的其他工作流？
   - 我們如何處理進程應該持續的案例（dev 伺服器）？

4. **技能閱讀執行：**
   - 我們應要求所有 subagents 讀相關技能？
   - 我們如何保持提示不變得太長？
   - 過度文檔化和失去焦點的風險？

---

## 成功指標

我們如何知道這些改進工作？

1. **配置驗證：**
   - 零「測試通過但使用了錯誤配置」實例
   - Jesse 不說「那實際上不測試你認為的」

2. **流程衛生：**
   - 零「測試撞上錯誤伺服器」實例
   - E2E 測試運行期間無端口衝突錯誤

3. **模擬-接口分歧：**
   - 零「測試通過但運行時在缺失方法上崩潰」實例
   - 模擬和接口之間無方法名不匹配

4. **自反思：**
   - 可測量：實現者報告是否包括自反思發現？
   - 定性：更少的錯誤達到代碼審查？

5. **技能閱讀：**
   - Subagent 報告引用技能門函數
   - 代碼審查中更少的反模式違反

---

## 風險和減輕

### 風險：提示膨脹
**問題：** 添加所有這些要求使提示令人難以承受
**減輕：**
- 分階段實現（不一次添加所有）
- 使某些添加有條件（E2E 衛生只用於 E2E 測試）
- 考慮不同任務類型的模板

### 風險：分析癱瘓
**問題：** 太多反思/驗證減慢執行
**減輕：**
- 保持門函數快速（秒，不分鐘）
- 初始使精簡上下文選擇加入
- 監控任務完成時間

### 風險：假安全感
**問題：** 遵循檢查清單不保證正確性
**減輕：**
- 強調門函數是最小值，不最大值
- 在技能中保留「使用判斷」語言
- 文檔技能捕獲常見失敗，不是所有失敗

### 風險：技能分歧
**問題：** 不同技能給衝突建議
**減輕：**
- 審查所有技能更改的一致性
- 文檔技能如何相互作用（集成部分）
- 在部署前用實際場景測試

---

## 推薦

**立即進行階段 1：**
- verification-before-completion：配置變更驗證
- testing-anti-patterns：模擬-接口分歧
- requesting-code-review：顯式文件閱讀

**在 Jesse 前測試階段 2：**
- 獲得自反思影響的反饋
- 驗證流程衛生方法
- 確認技能閱讀要求是值得開銷

**保持階段 3 待驗證：**
- 精簡上下文需要真實世界測試
- 實現者修復工作流改變需要仔細評估

這些改變解決用戶記錄的真實問題，同時最小化使技能更差的風險。
